

# Lexical Analysis in Python

According to [Wikipedia](https://en.wikipedia.org/wiki/Lexical_analysis): "In computer science, lexical analysis, lexing or tokenization is the 
process of converting a sequence of characters (such as in a computer program or web page) 
into a sequence of tokens (strings with an assigned and thus identified meaning). 
A program that performs lexical analysis may be termed a lexer, tokenizer, or scanner, 
although scanner is also a term for the first stage of a lexer. 
A lexer is generally combined with a parser, which together analyze the syntax of programming languages" 


## Pygments package

[Pygments package](https://pygments.org/) provides [a set of Lexers for different programming languages](https://pygments.org/docs/lexers/) implemented in Python.
To install this package in you virtual environment, execute this command:

    pip install Pygments

An example of using Python Lexer to do the lexical analysis of the simple Python program
can be found [inside `tokenizer.py` modules](https://github.com/vladaindjic/SPC-exchange-students/blob/master/LexerExample/tokenizer.py). For more information, see the source code
of the module.

